{
    "summary": "The code imports libraries, handles user inputs and directory creation, verifies grid images, populates lists from XML tree, manages UI elements, replaces placeholders with data, handles actions like tap/text/long press, logs and parses responses based on grid setting, checks for errors, and prints success or error messages.",
    "details": [
        {
            "comment": "Code imports necessary libraries, sets up argument parsing for executing the AppAgent tasks. It defines the description of the executor, loads configuration from config file and gets the name of app to be operated. If no app name is given, it prompts user for input and proceeds with executing tasks for specified app. It also creates work directory if it does not exist and defines auto_docs_dir in the app directory.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":0-35",
            "content": "import argparse\nimport ast\nimport datetime\nimport json\nimport os\nimport re\nimport sys\nimport time\nimport prompts\nfrom config import load_config\nfrom and_controller import list_all_devices, AndroidController, traverse_tree\nfrom model import ask_gpt4v, parse_explore_rsp, parse_grid_rsp\nfrom utils import print_with_color, draw_bbox_multi, encode_image, draw_grid\narg_desc = \"AppAgent Executor\"\nparser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=arg_desc)\nparser.add_argument(\"--app\")\nparser.add_argument(\"--root_dir\", default=\"./\")\nargs = vars(parser.parse_args())\nconfigs = load_config()\napp = args[\"app\"]\nroot_dir = args[\"root_dir\"]\nif not app:\n    print_with_color(\"What is the name of the app you want me to operate?\", \"blue\")\n    app = input()\n    app = app.replace(\" \", \"\")\napp_dir = os.path.join(os.path.join(root_dir, \"apps\"), app)\nwork_dir = os.path.join(root_dir, \"tasks\")\nif not os.path.exists(work_dir):\n    os.mkdir(work_dir)\nauto_docs_dir = os.path.join(app_dir, \"auto_docs\")"
        },
        {
            "comment": "Creating a new task directory with a timestamped name, checking for documentation directories, and asking user to choose which documentation to use or if no documents are found, prompting the user whether to proceed without documents.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":36-56",
            "content": "demo_docs_dir = os.path.join(app_dir, \"demo_docs\")\ntask_timestamp = int(time.time())\ndir_name = datetime.datetime.fromtimestamp(task_timestamp).strftime(f\"task_{app}_%Y-%m-%d_%H-%M-%S\")\ntask_dir = os.path.join(work_dir, dir_name)\nos.mkdir(task_dir)\nlog_path = os.path.join(task_dir, f\"log_{app}_{dir_name}.txt\")\nno_doc = False\nif not os.path.exists(auto_docs_dir) and not os.path.exists(demo_docs_dir):\n    print_with_color(f\"No documentations found for the app {app}. Do you want to proceed with no docs? Enter y or n\",\n                     \"red\")\n    user_input = \"\"\n    while user_input != \"y\" and user_input != \"n\":\n        user_input = input().lower()\n    if user_input == \"y\":\n        no_doc = True\n    else:\n        sys.exit()\nelif os.path.exists(auto_docs_dir) and os.path.exists(demo_docs_dir):\n    print_with_color(f\"The app {app} has documentations generated from both autonomous exploration and human \"\n                     f\"demonstration. Which one do you want to use? Type 1 or 2.\\n1. Autonomous exploration\\n2. Human \""
        },
        {
            "comment": "This code snippet prompts the user to select a document base from either automatically generated ones or demonstration ones. It then checks if any devices are attached and prints relevant messages based on the conditions met.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":57-82",
            "content": "                     f\"Demonstration\",\n                     \"blue\")\n    user_input = \"\"\n    while user_input != \"1\" and user_input != \"2\":\n        user_input = input()\n    if user_input == \"1\":\n        docs_dir = auto_docs_dir\n    else:\n        docs_dir = demo_docs_dir\nelif os.path.exists(auto_docs_dir):\n    print_with_color(f\"Documentations generated from autonomous exploration were found for the app {app}. The doc base \"\n                     f\"is selected automatically.\", \"yellow\")\n    docs_dir = auto_docs_dir\nelse:\n    print_with_color(f\"Documentations generated from human demonstration were found for the app {app}. The doc base is \"\n                     f\"selected automatically.\", \"yellow\")\n    docs_dir = demo_docs_dir\ndevice_list = list_all_devices()\nif not device_list:\n    print_with_color(\"ERROR: No device found!\", \"red\")\n    sys.exit()\nprint_with_color(f\"List of devices attached:\\n{str(device_list)}\", \"yellow\")\nif len(device_list) == 1:\n    device = device_list[0]\n    print_with_color(f\"Device selected: {device}\", \"yellow\")"
        },
        {
            "comment": "User is prompted to choose an Android device for the demo by entering its ID. The device size is checked and if it's invalid, an error is displayed and the program exits. Otherwise, user is asked to provide a task description in a few sentences. A function `area_to_xy` is defined to convert area number to x-y coordinates on the screen. \n\nStorage location: \"AppAgent/scripts/task_executor.py\":115-142\nCode:\n```\ndef get_subarea(area):\n    while True:\n        try:\n            subarea = input(\"Please enter the subarea (top, top-left, top-right) for area \" + str(area+1) + \":\").lower()\n            if subarea in (\"top\", \"top-left\", \"top-right\"):\n                return subarea\n        except Exception as e:\n            print_with_color(\"ERROR:\", \"red\")\n            print(e)\n```\nComment for code:\n\nThe function `get_subarea` prompts the user to enter the sub-areas for each area in a loop until valid input is provided. Valid inputs are 'top', 'top-left' or 'top-right'. If invalid input is entered, an error message is displayed along with the exception and the program continues to prompt until valid input is given.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":83-112",
            "content": "else:\n    print_with_color(\"Please choose the Android device to start demo by entering its ID:\", \"blue\")\n    device = input()\ncontroller = AndroidController(device)\nwidth, height = controller.get_device_size()\nif not width and not height:\n    print_with_color(\"ERROR: Invalid device size!\", \"red\")\n    sys.exit()\nprint_with_color(f\"Screen resolution of {device}: {width}x{height}\", \"yellow\")\nprint_with_color(\"Please enter the description of the task you want me to complete in a few sentences:\", \"blue\")\ntask_desc = input()\nround_count = 0\nlast_act = \"None\"\ntask_complete = False\ngrid_on = False\nrows, cols = 0, 0\ndef area_to_xy(area, subarea):\n    area -= 1\n    row, col = area // cols, area % cols\n    x_0, y_0 = col * (width // cols), row * (height // rows)\n    if subarea == \"top-left\":\n        x, y = x_0 + (width // cols) // 4, y_0 + (height // rows) // 4\n    elif subarea == \"top\":\n        x, y = x_0 + (width // cols) // 2, y_0 + (height // rows) // 4\n    elif subarea == \"top-right\":\n        x, y = x_0 + (width // cols) * 3 // 4, y_0 + (height // rows) // 4"
        },
        {
            "comment": "Code calculates the coordinates for subareas of a screenshot and continues with round processing. It checks if screenshots or XML paths are errors, then breaks if so. If grid is on, it draws the grid.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":113-136",
            "content": "    elif subarea == \"left\":\n        x, y = x_0 + (width // cols) // 4, y_0 + (height // rows) // 2\n    elif subarea == \"right\":\n        x, y = x_0 + (width // cols) * 3 // 4, y_0 + (height // rows) // 2\n    elif subarea == \"bottom-left\":\n        x, y = x_0 + (width // cols) // 4, y_0 + (height // rows) * 3 // 4\n    elif subarea == \"bottom\":\n        x, y = x_0 + (width // cols) // 2, y_0 + (height // rows) * 3 // 4\n    elif subarea == \"bottom-right\":\n        x, y = x_0 + (width // cols) * 3 // 4, y_0 + (height // rows) * 3 // 4\n    else:\n        x, y = x_0 + (width // cols) // 2, y_0 + (height // rows) // 2\n    return x, y\nwhile round_count < configs[\"MAX_ROUNDS\"]:\n    round_count += 1\n    print_with_color(f\"Round {round_count}\", \"yellow\")\n    screenshot_path = controller.get_screenshot(f\"{dir_name}_{round_count}\", task_dir)\n    xml_path = controller.get_xml(f\"{dir_name}_{round_count}\", task_dir)\n    if screenshot_path == \"ERROR\" or xml_path == \"ERROR\":\n        break\n    if grid_on:\n        rows, cols = draw_grid(screenshot_path, os.path.join(task_dir, f\"{dir_name}_{round_count}_grid.png\"))"
        },
        {
            "comment": "If `os.path.join(task_dir, f\"{dir_name}_{round_count}_grid.png\")` exists:\n- Encode the image using `encode_image()`.\n- Set prompt to `prompts.task_template_grid`.\nElse:\n- Create empty `clickable_list` and `focusable_list`.\n- Traverse XML tree to populate `clickable_list` and `focusable_list`.\n- Combine `clickable_list` and `focusable_list` into `elem_list`, excluding duplicates.\n- Draw bounding boxes for elements in `elem_list` on `screenshot_path` and save as `os.path.join(task_dir, f\"{dir_name}_{round_count}_labeled.png\")`.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":137-158",
            "content": "        base64_img = encode_image(os.path.join(task_dir, f\"{dir_name}_{round_count}_grid.png\"))\n        prompt = prompts.task_template_grid\n    else:\n        clickable_list = []\n        focusable_list = []\n        traverse_tree(xml_path, clickable_list, \"clickable\", True)\n        traverse_tree(xml_path, focusable_list, \"focusable\", True)\n        elem_list = clickable_list.copy()\n        for elem in focusable_list:\n            bbox = elem.bbox\n            center = (bbox[0][0] + bbox[1][0]) // 2, (bbox[0][1] + bbox[1][1]) // 2\n            close = False\n            for e in clickable_list:\n                bbox = e.bbox\n                center_ = (bbox[0][0] + bbox[1][0]) // 2, (bbox[0][1] + bbox[1][1]) // 2\n                dist = (abs(center[0] - center_[0]) ** 2 + abs(center[1] - center_[1]) ** 2) ** 0.5\n                if dist <= configs[\"MIN_DIST\"]:\n                    close = True\n                    break\n            if not close:\n                elem_list.append(elem)\n        draw_bbox_multi(screenshot_path, os.path.join(task_dir, f\"{dir_name}_{round_count}_labeled.png\"), elem_list,"
        },
        {
            "comment": "This code is checking if there are any documentation files for UI elements and constructing the prompt accordingly. If there are no documentation files, it removes the \"<ui_document>\" placeholder from the task template. Otherwise, it adds a formatted documentation section to the prompt, listing each element's documentation file path and content.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":159-174",
            "content": "                        dark_mode=configs[\"DARK_MODE\"])\n        base64_img = encode_image(os.path.join(task_dir, f\"{dir_name}_{round_count}_labeled.png\"))\n        if no_doc:\n            prompt = re.sub(r\"<ui_document>\", \"\", prompts.task_template)\n        else:\n            ui_doc = \"\"\"\n            You also have access to the following documentations that describes the functionalities of UI \n            elements you can interact on the screen. These docs are crucial for you to determine the target of your \n            next action. You should always prioritize these documented elements for interaction:\"\"\"\n            for i, elem in enumerate(elem_list):\n                doc_path = os.path.join(docs_dir, f\"{elem.uid}.txt\")\n                if not os.path.exists(doc_path):\n                    continue\n                ui_doc += f\"Documentation of UI element labeled with the numeric tag '{i + 1}':\\n\"\n                doc_content = ast.literal_eval(open(doc_path, \"r\").read())\n                if doc_content[\"tap\"]:"
        },
        {
            "comment": "This code retrieves UI documentation for an interface and prints it in color. It includes clickability, text input, long press, vertical swipe, and horizontal swipe information.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":175-187",
            "content": "                    ui_doc += f\"This UI element is clickable. {doc_content['tap']}\\n\\n\"\n                if doc_content[\"text\"]:\n                    ui_doc += f\"This UI element can receive text input. The text input is used for the following \" \\\n                              f\"purposes: {doc_content['text']}\\n\\n\"\n                if doc_content[\"long_press\"]:\n                    ui_doc += f\"This UI element is long clickable. {doc_content['long_press']}\\n\\n\"\n                if doc_content[\"v_swipe\"]:\n                    ui_doc += f\"This element can be swiped directly without tapping. You can swipe vertically on \" \\\n                              f\"this UI element. {doc_content['v_swipe']}\\n\\n\"\n                if doc_content[\"h_swipe\"]:\n                    ui_doc += f\"This element can be swiped directly without tapping. You can swipe horizontally on \" \\\n                              f\"this UI element. {doc_content['h_swipe']}\\n\\n\"\n            print_with_color(f\"Documentations retrieved for the current interface:\\n{ui_doc}\", \"magenta\")"
        },
        {
            "comment": "This code is creating a prompt by replacing placeholders with relevant information, then sending it to an AI model for response. If there's no error in the response, log the prompt, image, and response, and parse the response based on the grid setting. If the action name is \"FINISH\", set task_complete to True.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":188-217",
            "content": "            prompt = re.sub(r\"<ui_document>\", ui_doc, prompts.task_template)\n    prompt = re.sub(r\"<task_description>\", task_desc, prompt)\n    prompt = re.sub(r\"<last_act>\", last_act, prompt)\n    content = [\n        {\n            \"type\": \"text\",\n            \"text\": prompt\n        },\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_img}\"\n            }\n        }\n    ]\n    print_with_color(\"Thinking about what to do in the next step...\", \"yellow\")\n    rsp = ask_gpt4v(content)\n    if \"error\" not in rsp:\n        with open(log_path, \"a\") as logfile:\n            log_item = {\"step\": round_count, \"prompt\": prompt, \"image\": f\"{dir_name}_{round_count}_labeled.png\",\n                        \"response\": rsp}\n            logfile.write(json.dumps(log_item) + \"\\n\")\n        if grid_on:\n            res = parse_grid_rsp(rsp)\n        else:\n            res = parse_explore_rsp(rsp)\n        act_name = res[0]\n        if act_name == \"FINISH\":\n            task_complete = True"
        },
        {
            "comment": "Code handles various actions such as tap, text, and long press based on the given action name. It also checks for errors during execution and breaks if an error occurs.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":218-244",
            "content": "            break\n        if act_name == \"ERROR\":\n            break\n        last_act = res[-1]\n        res = res[:-1]\n        if act_name == \"tap\":\n            _, area = res\n            tl, br = elem_list[area - 1].bbox\n            x, y = (tl[0] + br[0]) // 2, (tl[1] + br[1]) // 2\n            ret = controller.tap(x, y)\n            if ret == \"ERROR\":\n                print_with_color(\"ERROR: tap execution failed\", \"red\")\n                break\n        elif act_name == \"text\":\n            _, input_str = res\n            ret = controller.text(input_str)\n            if ret == \"ERROR\":\n                print_with_color(\"ERROR: text execution failed\", \"red\")\n                break\n        elif act_name == \"long_press\":\n            _, area = res\n            tl, br = elem_list[area - 1].bbox\n            x, y = (tl[0] + br[0]) // 2, (tl[1] + br[1]) // 2\n            ret = controller.long_press(x, y)\n            if ret == \"ERROR\":\n                print_with_color(\"ERROR: long press execution failed\", \"red\")\n                break"
        },
        {
            "comment": "This code handles different types of actions such as \"swipe\", \"grid\", \"tap_grid\", and \"long_press_grid\". If the action is \"swipe\", it executes a swipe on the screen with specified direction and distance. If it fails, it prints an error message. For grid-related actions, it maps the area and subarea to coordinates and performs either a tap or long press accordingly. Again, if there's an error, it prints an error message.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":245-268",
            "content": "        elif act_name == \"swipe\":\n            _, area, swipe_dir, dist = res\n            tl, br = elem_list[area - 1].bbox\n            x, y = (tl[0] + br[0]) // 2, (tl[1] + br[1]) // 2\n            ret = controller.swipe(x, y, swipe_dir, dist)\n            if ret == \"ERROR\":\n                print_with_color(\"ERROR: swipe execution failed\", \"red\")\n                break\n        elif act_name == \"grid\":\n            grid_on = True\n        elif act_name == \"tap_grid\" or act_name == \"long_press_grid\":\n            _, area, subarea = res\n            x, y = area_to_xy(area, subarea)\n            if act_name == \"tap_grid\":\n                ret = controller.tap(x, y)\n                if ret == \"ERROR\":\n                    print_with_color(\"ERROR: tap execution failed\", \"red\")\n                    break\n            else:\n                ret = controller.long_press(x, y)\n                if ret == \"ERROR\":\n                    print_with_color(\"ERROR: tap execution failed\", \"red\")\n                    break\n        elif act_name == \"swipe_grid\":"
        },
        {
            "comment": "This code executes a swipe action with precise coordinates, checks for errors, and prints error or success messages based on task completion status.",
            "location": "\"/media/root/Toshiba XG3/works/AppAgent/docs/src/scripts/task_executor.py\":269-288",
            "content": "            _, start_area, start_subarea, end_area, end_subarea = res\n            start_x, start_y = area_to_xy(start_area, start_subarea)\n            end_x, end_y = area_to_xy(end_area, end_subarea)\n            ret = controller.swipe_precise((start_x, start_y), (end_x, end_y))\n            if ret == \"ERROR\":\n                print_with_color(\"ERROR: tap execution failed\", \"red\")\n                break\n        if act_name != \"grid\":\n            grid_on = False\n        time.sleep(configs[\"REQUEST_INTERVAL\"])\n    else:\n        print_with_color(rsp[\"error\"][\"message\"], \"red\")\n        break\nif task_complete:\n    print_with_color(\"Task completed successfully\", \"yellow\")\nelif round_count == configs[\"MAX_ROUNDS\"]:\n    print_with_color(\"Task finished due to reaching max rounds\", \"yellow\")\nelse:\n    print_with_color(\"Task finished unexpectedly\", \"red\")"
        }
    ]
}